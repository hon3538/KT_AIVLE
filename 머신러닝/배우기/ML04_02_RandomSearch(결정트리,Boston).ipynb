{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1J78TFSRrSA"
   },
   "source": [
    "<center><img src='https://raw.githubusercontent.com/Jangrae/img/master/ml_python.png' width=600/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8RKOTKcoclZ"
   },
   "source": [
    "<img src = \"https://github.com/Jangrae/img/blob/master/boston.png?raw=true\" width=800 align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30WC6LUaHGdk"
   },
   "source": [
    "# 실습 내용\n",
    "\n",
    "- Random Search로 Decision Tree 알고리즘 모델을 튜닝합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WW5MoKVRHuE8"
   },
   "source": [
    "# 1.환경 준비\n",
    "\n",
    "- 기본 라이브러리와 대상 데이터를 가져와 이후 과정을 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BzJjQX4lNdJr",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1yPDiJ4NNdJs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 읽어오기\n",
    "path = 'https://raw.githubusercontent.com/jangrae/csv/master/boston.csv'\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJOddHq2zfcU"
   },
   "source": [
    "# 2.데이터 이해\n",
    "\n",
    "- 분석할 데이터를 충분히 이해할 수 있도록 다양한 탐색 과정을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wzs1nS348uwE"
   },
   "outputs": [],
   "source": [
    "# 상위 몇 개 행 확인\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1DE266rocla"
   },
   "source": [
    "**데이터 설명**\n",
    "\n",
    "- crim: 자치시(Town)별 1인당 범죄율\n",
    "- zn: 25,000 평방피트를 초과하는 거주지역 비율\n",
    "- indus: 비소매상업지역이 점유하고 있는 토지 비율\n",
    "- chas: 찰스강에 대한 더미 변수 (= 1 강 경계에 위치; 0 나머지)\n",
    "- nox: 10ppm당 농축 일산화질소\n",
    "- rm: 주택 1가구당 평균 방 개수\n",
    "- age: 1940년 이전에 건축된 소유주택 비율\n",
    "- dis: 5개 보스턴 직업센터까지 접근성 지수\n",
    "- rad: 방사형 도로까지의 접근성 지수\n",
    "- tax: 10,000달러 당 재산세율\n",
    "- ptratio: 자치시(Town)별 학생/교사 비율\n",
    "- black: 1000(Bk - 0.63)^2, 여기서 Bk는 자치시별 흑인의 비율을 의미\n",
    "- lstat: 모집단 하위 계층의 비율(%)\n",
    "- medv: 본인 소유 주택가격(중앙값) (단위:$1,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LhAk04Uy4Occ"
   },
   "outputs": [],
   "source": [
    "# 기술통계 확인\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wW0d0eGmCYJM"
   },
   "source": [
    "# 3.데이터 준비\n",
    "\n",
    "- 전처리 과정을 통해 머신러닝 알고리즘에 사용할 수 있는 형태의 데이터를 준비합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cPr1J1RQyHa"
   },
   "source": [
    "**1) x, y 분리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fK-oriQsQyHw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# target 확인\n",
    "target = 'medv'\n",
    "\n",
    "# 데이터 분리\n",
    "x = data.drop(target, axis=1)\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nc6yw1RzQ7g1"
   },
   "source": [
    "**2) 학습용, 평가용 데이터 분리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Kx7xyBwfQ35W",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모듈 불러오기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 분리\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pmu6Di1MiyX4"
   },
   "source": [
    "# 4.성능 예측\n",
    "\n",
    "- k-Fold Cross Validation을 사용해 모델의 성능을 예측합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "46LrmqgIqgN2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 불러오기\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pZ0QQiliqgN3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 선언하기\n",
    "model_dt = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4FGBNX_RqgN4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 성능예측\n",
    "cv_score = cross_val_score(model_dt, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "df-rQHcwqgN4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64619845 0.60030644 0.74548942 0.84916342 0.85356022]\n",
      "0.7389435896396416\n"
     ]
    }
   ],
   "source": [
    "# 결과확인\n",
    "print(cv_score)\n",
    "print(cv_score.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-EyKFHUtpI2"
   },
   "source": [
    "# 5.모델 튜닝\n",
    "\n",
    "\n",
    "- Random Search로 튜닝을 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFYPwKfxRAfx"
   },
   "source": [
    "**1) 모델 튜닝**\n",
    "\n",
    "- 성능을 확인할 파라미터를 딕셔너리 형태로 선언합니다.\n",
    "- 기존 모델을 기본으로 RandomizedSearchCV 알고리즘을 사용하는 모델을 선언합니다.\n",
    "- 다음 정보를 최종 모델에 파라미터로 전달합니다.\n",
    "    - 기본 모델 이름\n",
    "    - 파라미터 변수\n",
    "    - cv: K-Fold 분할 개수(기본값=5)\n",
    "    - n_iter: 시도 횟수(기본값=10)\n",
    "    - scoring: 평가 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DecisionTreeRegressor in module sklearn.tree._classes object:\n",
      "\n",
      "class DecisionTreeRegressor(sklearn.base.RegressorMixin, BaseDecisionTree)\n",
      " |  DecisionTreeRegressor(*, criterion='squared_error', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, ccp_alpha=0.0)\n",
      " |  \n",
      " |  A decision tree regressor.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <tree>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  criterion : {\"squared_error\", \"friedman_mse\", \"absolute_error\",             \"poisson\"}, default=\"squared_error\"\n",
      " |      The function to measure the quality of a split. Supported criteria\n",
      " |      are \"squared_error\" for the mean squared error, which is equal to\n",
      " |      variance reduction as feature selection criterion and minimizes the L2\n",
      " |      loss using the mean of each terminal node, \"friedman_mse\", which uses\n",
      " |      mean squared error with Friedman's improvement score for potential\n",
      " |      splits, \"absolute_error\" for the mean absolute error, which minimizes\n",
      " |      the L1 loss using the median of each terminal node, and \"poisson\" which\n",
      " |      uses reduction in Poisson deviance to find splits.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Mean Absolute Error (MAE) criterion.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |          Poisson deviance criterion.\n",
      " |  \n",
      " |  splitter : {\"best\", \"random\"}, default=\"best\"\n",
      " |      The strategy used to choose the split at each node. Supported\n",
      " |      strategies are \"best\" to choose the best split and \"random\" to choose\n",
      " |      the best random split.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `max(1, int(max_features * n_features_in_))` features are considered at each\n",
      " |        split.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the randomness of the estimator. The features are always\n",
      " |      randomly permuted at each split, even if ``splitter`` is set to\n",
      " |      ``\"best\"``. When ``max_features < n_features``, the algorithm will\n",
      " |      select ``max_features`` at random at each split before finding the best\n",
      " |      split among them. But the best found split may vary across different\n",
      " |      runs, even if ``max_features=n_features``. That is the case, if the\n",
      " |      improvement of the criterion is identical for several splits and one\n",
      " |      split has to be selected at random. To obtain a deterministic behaviour\n",
      " |      during fitting, ``random_state`` has to be fixed to an integer.\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the\n",
      " |      (normalized) total reduction of the criterion brought\n",
      " |      by that feature. It is also known as the Gini importance [4]_.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  max_features_ : int\n",
      " |      The inferred value of max_features.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  tree_ : Tree instance\n",
      " |      The underlying Tree object. Please refer to\n",
      " |      ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
      " |      :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
      " |      for basic usage of these attributes.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DecisionTreeClassifier : A decision tree classifier.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
      " |  \n",
      " |  .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
      " |         and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
      " |  \n",
      " |  .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
      " |         Learning\", Springer, 2009.\n",
      " |  \n",
      " |  .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
      " |         https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_diabetes\n",
      " |  >>> from sklearn.model_selection import cross_val_score\n",
      " |  >>> from sklearn.tree import DecisionTreeRegressor\n",
      " |  >>> X, y = load_diabetes(return_X_y=True)\n",
      " |  >>> regressor = DecisionTreeRegressor(random_state=0)\n",
      " |  >>> cross_val_score(regressor, X, y, cv=10)\n",
      " |  ...                    # doctest: +SKIP\n",
      " |  ...\n",
      " |  array([-0.39..., -0.46...,  0.02...,  0.06..., -0.50...,\n",
      " |         0.16...,  0.11..., -0.73..., -0.30..., -0.00...])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DecisionTreeRegressor\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      BaseDecisionTree\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, criterion='squared_error', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, ccp_alpha=0.0)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, check_input=True)\n",
      " |      Build a decision tree regressor from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (real numbers). Use ``dtype=np.float64`` and\n",
      " |          ``order='C'`` for maximum efficiency.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you're doing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : DecisionTreeRegressor\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.tree._classes.DecisionTreeRegressor, *, check_input: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.tree._classes.DecisionTreeRegressor\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      check_input : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``check_input`` parameter in ``fit``.\n",
      " |      \n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_predict_request(self: sklearn.tree._classes.DecisionTreeRegressor, *, check_input: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.tree._classes.DecisionTreeRegressor\n",
      " |      Request metadata passed to the ``predict`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      check_input : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``check_input`` parameter in ``predict``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.tree._classes.DecisionTreeRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.tree._classes.DecisionTreeRegressor\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  apply(self, X, check_input=True)\n",
      " |      Return the index of the leaf that each sample is predicted as.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you're doing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array-like of shape (n_samples,)\n",
      " |          For each datapoint x in X, return the index of the leaf x\n",
      " |          ends up in. Leaves are numbered within\n",
      " |          ``[0; self.tree_.node_count)``, possibly with gaps in the\n",
      " |          numbering.\n",
      " |  \n",
      " |  cost_complexity_pruning_path(self, X, y, sample_weight=None)\n",
      " |      Compute the pruning path during Minimal Cost-Complexity Pruning.\n",
      " |      \n",
      " |      See :ref:`minimal_cost_complexity_pruning` for details on the pruning\n",
      " |      process.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels) as integers or strings.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. Splits are also\n",
      " |          ignored if they would result in any single class carrying a\n",
      " |          negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ccp_path : :class:`~sklearn.utils.Bunch`\n",
      " |          Dictionary-like object, with the following attributes.\n",
      " |      \n",
      " |          ccp_alphas : ndarray\n",
      " |              Effective alphas of subtree during pruning.\n",
      " |      \n",
      " |          impurities : ndarray\n",
      " |              Sum of the impurities of the subtree leaves for the\n",
      " |              corresponding alpha value in ``ccp_alphas``.\n",
      " |  \n",
      " |  decision_path(self, X, check_input=True)\n",
      " |      Return the decision path in the tree.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you're doing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator CSR matrix where non zero elements\n",
      " |          indicates that the samples goes through the nodes.\n",
      " |  \n",
      " |  get_depth(self)\n",
      " |      Return the depth of the decision tree.\n",
      " |      \n",
      " |      The depth of a tree is the maximum distance between the root\n",
      " |      and any leaf.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self.tree_.max_depth : int\n",
      " |          The maximum depth of the tree.\n",
      " |  \n",
      " |  get_n_leaves(self)\n",
      " |      Return the number of leaves of the decision tree.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self.tree_.n_leaves : int\n",
      " |          Number of leaves.\n",
      " |  \n",
      " |  predict(self, X, check_input=True)\n",
      " |      Predict class or regression value for X.\n",
      " |      \n",
      " |      For a classification model, the predicted class for each sample in X is\n",
      " |      returned. For a regression model, the predicted value based on X is\n",
      " |      returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you're doing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted classes, or the predict values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances.\n",
      " |      \n",
      " |      The importance of a feature is computed as the (normalized) total\n",
      " |      reduction of the criterion brought by that feature.\n",
      " |      It is also known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          Normalized total reduction of criteria by feature\n",
      " |          (Gini importance).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "V-PSKjBMbFYJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 파라미터 선언\n",
    "  # max_depth: 1~50\n",
    "param = {\n",
    "    'max_depth':range(1, 51),\n",
    "}\n",
    "\n",
    "# Random Search 선언\n",
    "  # cv=5\n",
    "  # n_iter=20\n",
    "  # scoring='r2'\n",
    "    \n",
    "model = RandomizedSearchCV(model_dt,     # 기본 모델\n",
    "                          param,         # 파라미터 범위\n",
    "                          cv=10,         # K-Fold 개수\n",
    "                          n_iter=20,     # 선택할 임의 파라미터\n",
    "                          scoring='r2')  # 평가 방법, \n",
    "# 만약 scoring을 MAE로 할 거라면 neg_mean_ab.. 이렇게 - 붙여줘야함, \n",
    "# 각 파라미터로 검증할 때마다 큰 값으로 베스트 파라미터로 설정하기 때문에\n",
    "\n",
    "# model = GridSearchCV(model_dt,     # 기본 모델\n",
    "#                           param,         # 파라미터 범위\n",
    "#                           cv=10,         # K-Fold 개수\n",
    "#                           scoring='r2')  # 평가 방법, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "tPmXseSQoclc",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: range(1, 51)}, scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: range(1, 51)}, scoring=&#x27;r2&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'max_depth': range(1, 51)}, scoring='r2')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습하기\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BLGo4F2Hjio"
   },
   "source": [
    "**2) 결과 확인**\n",
    "\n",
    "- model.cv_results_ 속성에 성능 테스트와 관련된 많은 정보가 포함되어 있습니다.\n",
    "- 이 중 중요한 정보를만 추출해서 확인합니다.\n",
    "- 다음 3가지는 꼭 기억해야 합니다.\n",
    "    - model.cv_results_['mean_test_score']: 테스트로 얻은 성능\n",
    "    - model.best_params_: 최적의 파라미터\n",
    "    - model.best_score_: 최고의 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "JBSJkCx6Jl5w",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[0.35165946 0.60497769 0.68200127 0.7732584  0.78427249 0.7576114\n",
      " 0.7518966  0.75027176 0.75533848 0.72219708 0.77126808 0.72842787\n",
      " 0.71823251 0.73383381 0.72487393 0.73355641 0.73278673 0.70901877\n",
      " 0.73656831 0.73382111 0.74514558 0.7206653  0.70707698 0.75068225\n",
      " 0.7175881  0.77878596 0.71081864 0.77222411 0.71647366 0.74351163\n",
      " 0.73674913 0.72642055 0.7200165  0.73261411 0.72363147 0.73133109\n",
      " 0.72621112 0.76308205 0.73220221 0.72387552 0.72220136 0.76693158\n",
      " 0.72925217 0.76542942 0.7120566  0.74216711 0.74939793 0.73544603\n",
      " 0.71906585 0.75541971]\n",
      "--------------------------------------------------------------------------------\n",
      "최적파라미터: {'max_depth': 5}\n",
      "--------------------------------------------------------------------------------\n",
      "최고성능: 0.7842724921375648\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00286696, 0.00309436, 0.00364275, 0.00422132, 0.00469506,\n",
       "        0.00563929, 0.00644369, 0.0068862 , 0.00712395, 0.00821536,\n",
       "        0.00888278, 0.00903766, 0.01005075, 0.00911591, 0.01027541,\n",
       "        0.00950382, 0.00996549, 0.00930159, 0.0099299 , 0.01093347,\n",
       "        0.01098304, 0.00975404, 0.00913894, 0.00952761, 0.00930924,\n",
       "        0.01098664, 0.01070924, 0.01121309, 0.01102059, 0.0099087 ,\n",
       "        0.01064382, 0.01073422, 0.01012831, 0.01112695, 0.0101547 ,\n",
       "        0.01018395, 0.01057844, 0.01054609, 0.00966623, 0.01014235,\n",
       "        0.01048982, 0.01074975, 0.00941427, 0.00925319, 0.00948138,\n",
       "        0.01015568, 0.01032534, 0.01012654, 0.00999649, 0.00988693]),\n",
       " 'std_fit_time': array([0.00055928, 0.0008108 , 0.00046554, 0.00055113, 0.00056948,\n",
       "        0.00083667, 0.00079357, 0.00072391, 0.00055425, 0.00063709,\n",
       "        0.00067442, 0.00049321, 0.00122906, 0.00078778, 0.00198787,\n",
       "        0.00105533, 0.00085974, 0.00083492, 0.00087568, 0.0008049 ,\n",
       "        0.00177999, 0.00070804, 0.00054691, 0.00081418, 0.00092895,\n",
       "        0.00080033, 0.00128761, 0.00068371, 0.0007442 , 0.00152994,\n",
       "        0.00069422, 0.00057859, 0.00080097, 0.00129862, 0.00065897,\n",
       "        0.00103389, 0.00047934, 0.00109478, 0.00094064, 0.00079839,\n",
       "        0.0009086 , 0.0011952 , 0.00048681, 0.00091509, 0.00056299,\n",
       "        0.00114531, 0.00070717, 0.00084457, 0.0010048 , 0.00133569]),\n",
       " 'mean_score_time': array([0.00204589, 0.00187259, 0.00191491, 0.00176995, 0.00214875,\n",
       "        0.0017333 , 0.00193045, 0.00211818, 0.00171766, 0.00202861,\n",
       "        0.0019695 , 0.00207319, 0.00258667, 0.0021385 , 0.00249393,\n",
       "        0.00210013, 0.00217769, 0.00192473, 0.00201797, 0.00209999,\n",
       "        0.00237079, 0.00172341, 0.00200131, 0.00238934, 0.0025378 ,\n",
       "        0.0025245 , 0.00231917, 0.00212085, 0.00191948, 0.00245609,\n",
       "        0.00214784, 0.00215023, 0.00210507, 0.00244548, 0.00194266,\n",
       "        0.00232577, 0.00205684, 0.00233088, 0.00196886, 0.00224311,\n",
       "        0.0023962 , 0.00230784, 0.00204217, 0.00197396, 0.00216608,\n",
       "        0.0022537 , 0.00230489, 0.00202186, 0.00205932, 0.00187252]),\n",
       " 'std_score_time': array([0.00049688, 0.00059163, 0.00057949, 0.00053322, 0.00063065,\n",
       "        0.00050552, 0.00093614, 0.00048484, 0.00052009, 0.0004297 ,\n",
       "        0.00067933, 0.00041351, 0.00053773, 0.00041934, 0.00045295,\n",
       "        0.00029297, 0.0005804 , 0.00077498, 0.00064372, 0.00048996,\n",
       "        0.00057476, 0.00035209, 0.00067682, 0.00050782, 0.00142766,\n",
       "        0.00067917, 0.00089268, 0.00029023, 0.00041035, 0.00063363,\n",
       "        0.00048578, 0.00037139, 0.00047776, 0.00069469, 0.00040074,\n",
       "        0.00044099, 0.00063913, 0.00094588, 0.00040017, 0.00082159,\n",
       "        0.00079903, 0.00043077, 0.00043809, 0.00039491, 0.00049892,\n",
       "        0.0008944 , 0.00054982, 0.00064414, 0.00041483, 0.00061438]),\n",
       " 'param_max_depth': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
       "                    17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                    31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,\n",
       "                    45, 46, 47, 48, 49, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 1},\n",
       "  {'max_depth': 2},\n",
       "  {'max_depth': 3},\n",
       "  {'max_depth': 4},\n",
       "  {'max_depth': 5},\n",
       "  {'max_depth': 6},\n",
       "  {'max_depth': 7},\n",
       "  {'max_depth': 8},\n",
       "  {'max_depth': 9},\n",
       "  {'max_depth': 10},\n",
       "  {'max_depth': 11},\n",
       "  {'max_depth': 12},\n",
       "  {'max_depth': 13},\n",
       "  {'max_depth': 14},\n",
       "  {'max_depth': 15},\n",
       "  {'max_depth': 16},\n",
       "  {'max_depth': 17},\n",
       "  {'max_depth': 18},\n",
       "  {'max_depth': 19},\n",
       "  {'max_depth': 20},\n",
       "  {'max_depth': 21},\n",
       "  {'max_depth': 22},\n",
       "  {'max_depth': 23},\n",
       "  {'max_depth': 24},\n",
       "  {'max_depth': 25},\n",
       "  {'max_depth': 26},\n",
       "  {'max_depth': 27},\n",
       "  {'max_depth': 28},\n",
       "  {'max_depth': 29},\n",
       "  {'max_depth': 30},\n",
       "  {'max_depth': 31},\n",
       "  {'max_depth': 32},\n",
       "  {'max_depth': 33},\n",
       "  {'max_depth': 34},\n",
       "  {'max_depth': 35},\n",
       "  {'max_depth': 36},\n",
       "  {'max_depth': 37},\n",
       "  {'max_depth': 38},\n",
       "  {'max_depth': 39},\n",
       "  {'max_depth': 40},\n",
       "  {'max_depth': 41},\n",
       "  {'max_depth': 42},\n",
       "  {'max_depth': 43},\n",
       "  {'max_depth': 44},\n",
       "  {'max_depth': 45},\n",
       "  {'max_depth': 46},\n",
       "  {'max_depth': 47},\n",
       "  {'max_depth': 48},\n",
       "  {'max_depth': 49},\n",
       "  {'max_depth': 50}],\n",
       " 'split0_test_score': array([0.23756334, 0.41777718, 0.47616502, 0.68688555, 0.71324458,\n",
       "        0.67456129, 0.70791175, 0.67135644, 0.6713477 , 0.65357507,\n",
       "        0.66462927, 0.64659027, 0.65129237, 0.64573332, 0.62826026,\n",
       "        0.67183735, 0.64951846, 0.64091344, 0.63764795, 0.62582124,\n",
       "        0.68098862, 0.64750729, 0.65349027, 0.62404701, 0.63455764,\n",
       "        0.65538129, 0.67139429, 0.63450824, 0.62653093, 0.64747585,\n",
       "        0.61844582, 0.63427017, 0.65189122, 0.65252455, 0.62484653,\n",
       "        0.62379098, 0.6406619 , 0.65903755, 0.63567159, 0.63428365,\n",
       "        0.62715079, 0.6641177 , 0.65148247, 0.62921249, 0.6449515 ,\n",
       "        0.61907017, 0.66253661, 0.64878743, 0.66010658, 0.61351391]),\n",
       " 'split1_test_score': array([0.2448553 , 0.44902965, 0.65358722, 0.70384347, 0.70845361,\n",
       "        0.61351536, 0.65234052, 0.63225614, 0.62404823, 0.67156833,\n",
       "        0.67213107, 0.59134443, 0.62422036, 0.59381013, 0.65345288,\n",
       "        0.61912085, 0.62784453, 0.58050929, 0.60645449, 0.63379685,\n",
       "        0.6538548 , 0.55602251, 0.57111191, 0.5840424 , 0.62900437,\n",
       "        0.65503378, 0.62069027, 0.59773081, 0.62669235, 0.62457937,\n",
       "        0.62114962, 0.57714078, 0.54123933, 0.66060714, 0.62396309,\n",
       "        0.60065911, 0.59266655, 0.59270866, 0.63230398, 0.59385702,\n",
       "        0.55699861, 0.63328774, 0.6400975 , 0.62861011, 0.65137053,\n",
       "        0.59301872, 0.60341134, 0.59957966, 0.60283716, 0.63646869]),\n",
       " 'split2_test_score': array([0.47321009, 0.81053156, 0.84884302, 0.90054717, 0.92449088,\n",
       "        0.91789318, 0.92299212, 0.88943959, 0.89419871, 0.90405209,\n",
       "        0.89928409, 0.89173704, 0.87755508, 0.88601252, 0.89016947,\n",
       "        0.88865711, 0.8802743 , 0.89990196, 0.89700433, 0.88682194,\n",
       "        0.90203198, 0.89759911, 0.89850398, 0.89583257, 0.88805979,\n",
       "        0.89519712, 0.89362884, 0.90421283, 0.90842457, 0.915933  ,\n",
       "        0.91230588, 0.89096251, 0.91219404, 0.91208728, 0.88899517,\n",
       "        0.88737859, 0.88214505, 0.8912904 , 0.9180071 , 0.91127137,\n",
       "        0.90981747, 0.90520413, 0.91974822, 0.91305316, 0.9125626 ,\n",
       "        0.90513804, 0.89483873, 0.89876833, 0.89048211, 0.89691028]),\n",
       " 'split3_test_score': array([0.38221574, 0.65093719, 0.77018325, 0.74567462, 0.7871317 ,\n",
       "        0.76527197, 0.81637624, 0.76219056, 0.7768692 , 0.7850515 ,\n",
       "        0.82523622, 0.79932053, 0.78688516, 0.83904365, 0.77742912,\n",
       "        0.83393146, 0.79904669, 0.79729378, 0.81373605, 0.8461254 ,\n",
       "        0.82577414, 0.79455486, 0.79942794, 0.79051879, 0.76835328,\n",
       "        0.84009978, 0.83648441, 0.82112456, 0.7710177 , 0.77769627,\n",
       "        0.85073993, 0.82591876, 0.84559953, 0.80951593, 0.80935816,\n",
       "        0.84463981, 0.7961281 , 0.80219754, 0.8041345 , 0.82740873,\n",
       "        0.78713568, 0.80358672, 0.79801685, 0.79795112, 0.83810146,\n",
       "        0.83154997, 0.82236912, 0.82318422, 0.84342154, 0.79788977]),\n",
       " 'split4_test_score': array([0.36951527, 0.64886041, 0.3386462 , 0.45506942, 0.44286874,\n",
       "        0.39612451, 0.39647364, 0.7329042 , 0.58529424, 0.28438869,\n",
       "        0.64514066, 0.30932661, 0.28159218, 0.31970975, 0.2539581 ,\n",
       "        0.36086836, 0.28152387, 0.27743891, 0.26932298, 0.25505855,\n",
       "        0.30232607, 0.3139972 , 0.30339291, 0.59943285, 0.31809551,\n",
       "        0.65657012, 0.2517764 , 0.68502507, 0.3031947 , 0.31420707,\n",
       "        0.30072289, 0.2613022 , 0.31710445, 0.34776888, 0.25223112,\n",
       "        0.30289738, 0.33478605, 0.65721722, 0.31075587, 0.32591902,\n",
       "        0.31049353, 0.64073072, 0.27707747, 0.60262755, 0.24725836,\n",
       "        0.31931392, 0.69411946, 0.60300065, 0.28749521, 0.65427903]),\n",
       " 'split5_test_score': array([0.40653581, 0.58303984, 0.71751423, 0.81802836, 0.83884093,\n",
       "        0.83595595, 0.77650162, 0.74135218, 0.72569675, 0.83530728,\n",
       "        0.74318555, 0.81646637, 0.78113883, 0.81681136, 0.75325803,\n",
       "        0.75135484, 0.82273754, 0.84362721, 0.8383143 , 0.82089889,\n",
       "        0.84929324, 0.76745522, 0.75919213, 0.79706625, 0.72167756,\n",
       "        0.84053256, 0.76174104, 0.84396749, 0.75016501, 0.81095364,\n",
       "        0.79315621, 0.80713027, 0.75080063, 0.836584  , 0.81663893,\n",
       "        0.78688345, 0.77421915, 0.76402029, 0.79050136, 0.8540893 ,\n",
       "        0.76641832, 0.8161253 , 0.7595613 , 0.82675111, 0.76499299,\n",
       "        0.84009276, 0.73634824, 0.76576023, 0.82741562, 0.7627651 ]),\n",
       " 'split6_test_score': array([0.41940874, 0.68159665, 0.77380231, 0.86826102, 0.90365772,\n",
       "        0.86714358, 0.83361367, 0.64339844, 0.84691333, 0.63871285,\n",
       "        0.85226766, 0.83040711, 0.7373533 , 0.81966602, 0.81807508,\n",
       "        0.79730801, 0.84958407, 0.66656546, 0.83391289, 0.85352224,\n",
       "        0.82440366, 0.80128984, 0.72169982, 0.83738244, 0.76732204,\n",
       "        0.83676828, 0.62854015, 0.82826033, 0.7397927 , 0.87221763,\n",
       "        0.84698482, 0.82011329, 0.78068503, 0.64287532, 0.7894666 ,\n",
       "        0.84860608, 0.84190275, 0.81060697, 0.81543872, 0.6583835 ,\n",
       "        0.86714429, 0.79757579, 0.79267418, 0.8070239 , 0.66040061,\n",
       "        0.86049917, 0.62700622, 0.62740498, 0.63327003, 0.78648314]),\n",
       " 'split7_test_score': array([0.43496195, 0.77925653, 0.78181125, 0.81953861, 0.81795905,\n",
       "        0.80443853, 0.75078602, 0.7718297 , 0.76593513, 0.79587046,\n",
       "        0.75655557, 0.79345357, 0.77566705, 0.76136154, 0.77980532,\n",
       "        0.76677753, 0.76373172, 0.75917118, 0.78322436, 0.76868729,\n",
       "        0.78466281, 0.78380737, 0.77268662, 0.78190306, 0.7916126 ,\n",
       "        0.75845195, 0.7727847 , 0.75913031, 0.7601138 , 0.77993336,\n",
       "        0.78489438, 0.76512386, 0.76363909, 0.78656713, 0.77160778,\n",
       "        0.75786349, 0.77598852, 0.77739973, 0.77608932, 0.76220336,\n",
       "        0.76412947, 0.77817344, 0.78512595, 0.78052727, 0.77665871,\n",
       "        0.77985436, 0.78055451, 0.76298253, 0.78133367, 0.76427114]),\n",
       " 'split8_test_score': array([0.15124496, 0.37634841, 0.73787456, 0.85415852, 0.79137522,\n",
       "        0.81949424, 0.80593451, 0.79972899, 0.79792215, 0.80665455,\n",
       "        0.80839444, 0.7789831 , 0.80750824, 0.79539824, 0.83426345,\n",
       "        0.80496335, 0.82612771, 0.78967252, 0.84221364, 0.8248826 ,\n",
       "        0.79559289, 0.786558  , 0.77528606, 0.78883667, 0.81186958,\n",
       "        0.81048573, 0.83127119, 0.82911738, 0.81399564, 0.83107696,\n",
       "        0.7702397 , 0.83516608, 0.80659778, 0.82305828, 0.8121956 ,\n",
       "        0.82247907, 0.7774364 , 0.8344412 , 0.82455658, 0.81285804,\n",
       "        0.79788197, 0.80747872, 0.83510712, 0.82310337, 0.78965865,\n",
       "        0.84232463, 0.84423565, 0.80205779, 0.82305481, 0.77913586]),\n",
       " 'split9_test_score': array([0.39708342, 0.65239952, 0.72158567, 0.88057723, 0.91470248,\n",
       "        0.8817154 , 0.85603596, 0.85826132, 0.86515932, 0.84679001,\n",
       "        0.84585625, 0.82664968, 0.85911251, 0.86079159, 0.8600676 ,\n",
       "        0.84074522, 0.82747838, 0.83509396, 0.84385209, 0.82259615,\n",
       "        0.8325276 , 0.85786159, 0.81597811, 0.80776049, 0.84532863,\n",
       "        0.83933899, 0.83987512, 0.81916409, 0.86480921, 0.86104317,\n",
       "        0.8688521 , 0.84707762, 0.83041387, 0.85455257, 0.8470117 ,\n",
       "        0.83811294, 0.84617676, 0.84190096, 0.8145631 , 0.85848121,\n",
       "        0.83484347, 0.82303559, 0.83363061, 0.84543409, 0.83461057,\n",
       "        0.83080937, 0.82855941, 0.82293452, 0.84124179, 0.86248016]),\n",
       " 'mean_test_score': array([0.35165946, 0.60497769, 0.68200127, 0.7732584 , 0.78427249,\n",
       "        0.7576114 , 0.7518966 , 0.75027176, 0.75533848, 0.72219708,\n",
       "        0.77126808, 0.72842787, 0.71823251, 0.73383381, 0.72487393,\n",
       "        0.73355641, 0.73278673, 0.70901877, 0.73656831, 0.73382111,\n",
       "        0.74514558, 0.7206653 , 0.70707698, 0.75068225, 0.7175881 ,\n",
       "        0.77878596, 0.71081864, 0.77222411, 0.71647366, 0.74351163,\n",
       "        0.73674913, 0.72642055, 0.7200165 , 0.73261411, 0.72363147,\n",
       "        0.73133109, 0.72621112, 0.76308205, 0.73220221, 0.72387552,\n",
       "        0.72220136, 0.76693158, 0.72925217, 0.76542942, 0.7120566 ,\n",
       "        0.74216711, 0.74939793, 0.73544603, 0.71906585, 0.75541971]),\n",
       " 'std_test_score': array([0.09860128, 0.14032078, 0.14866749, 0.12716921, 0.13507299,\n",
       "        0.14954662, 0.13879924, 0.08126541, 0.09808324, 0.16846903,\n",
       "        0.08421196, 0.16352768, 0.16416753, 0.16371109, 0.17579378,\n",
       "        0.14560412, 0.16973421, 0.17218595, 0.17927726, 0.18061109,\n",
       "        0.16386711, 0.16445204, 0.15913461, 0.10232013, 0.15464463,\n",
       "        0.08663174, 0.17719358, 0.09525143, 0.16182318, 0.16807422,\n",
       "        0.17248661, 0.18090308, 0.166691  , 0.15577309, 0.1774704 ,\n",
       "        0.16930415, 0.15580535, 0.09099239, 0.16253565, 0.16669963,\n",
       "        0.16981859, 0.08549744, 0.17018783, 0.10103212, 0.1763516 ,\n",
       "        0.17136305, 0.09474809, 0.10164879, 0.17228028, 0.08914088]),\n",
       " 'rank_test_score': array([50, 49, 48,  3,  1,  9, 12, 14, 11, 37,  5, 30, 41, 22, 33, 24, 25,\n",
       "        46, 20, 23, 16, 38, 47, 13, 42,  2, 45,  4, 43, 17, 19, 31, 39, 26,\n",
       "        35, 28, 32,  8, 27, 34, 36,  6, 29,  7, 44, 18, 15, 21, 40, 10])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중요 정보 확인\n",
    "print('=' * 80)\n",
    "print(model.cv_results_['mean_test_score'])\n",
    "print('-' * 80)\n",
    "print('최적파라미터:', model.best_params_)\n",
    "print('-' * 80)\n",
    "print('최고성능:', model.best_score_)\n",
    "print('=' * 80)\n",
    "model.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwF7E59woclc"
   },
   "source": [
    "**3) 변수 중요도**\n",
    "\n",
    "- model.best_estimator_ 모델의 변수 중요도를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "s_frSxC_oclc",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 428,
       "width": 465
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 변수 중요도\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.barh(y=list(x), width=model.best_estimator_.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCnH_1KtB97j"
   },
   "source": [
    "# 6. 성능 평가\n",
    "\n",
    "- 학습을 통해 예상한 성능과 실제 평가에 따른 성능은 차이가 있을 수 있습니다.\n",
    "- 예선전에서 성적이 좋았다고 본선에서도 성적이 좋다고 보장할 수는 없겠지요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hL4VPE0ZbFYR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 예측하기\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "R1j5TCkObFYS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 2.7128606133767392\n",
      "R2-Score: 0.8627140711202218\n"
     ]
    }
   ],
   "source": [
    "# 평가하기\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred))\n",
    "print('R2-Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
