{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30aac96c-8df6-4e87-9f72-46c85206bdb0",
   "metadata": {},
   "source": [
    "# Hugging Face의 LLM 모델 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7c3b29-6ff4-40a3-8926-94f40f390e1c",
   "metadata": {},
   "source": [
    "### 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f970f5-284b-4e98-9a69-96a1bcbb1dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c096489-2c66-40c0-9233-6cc057de34e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  6 15:59:54 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 537.13                 Driver Version: 537.13       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080      WDDM  | 00000000:0A:00.0  On |                  N/A |\n",
      "| 35%   32C    P8              23W / 225W |   7885MiB /  8192MiB |      3%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1844    C+G   ...0_x64__wyx1vj98g3asy\\QuickShare.exe    N/A      |\n",
      "|    0   N/A  N/A      3492    C+G   ...on\\124.0.2478.80\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A      7576    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      9424    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9964    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11136    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     14520    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14568    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     15612    C+G   ...B\\system_tray\\lghub_system_tray.exe    N/A      |\n",
      "|    0   N/A  N/A     17252    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     18512    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe    N/A      |\n",
      "|    0   N/A  N/A     19396    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     19472    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     20604    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     20976      C   ...\\.conda\\envs\\LLM_project\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     21596    C+G   ...__wyx1vj98g3asy\\Win32\\QSSystray.exe    N/A      |\n",
      "|    0   N/A  N/A     23972    C+G   ...aam7r\\AcrobatNotificationClient.exe    N/A      |\n",
      "|    0   N/A  N/A     24408      C   ...\\.conda\\envs\\LLM_project\\python.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea9cf8b-f2dc-4b36-a339-3f7ea2fb25a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.3.0-cp39-cp39-win_amd64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch) (4.9.0)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch) (3.1.3)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Using cached tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.3.0-cp39-cp39-win_amd64.whl (159.7 MB)\n",
      "   ---------------------------------------- 0.0/159.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 4.4/159.7 MB 136.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 9.4/159.7 MB 119.3 MB/s eta 0:00:02\n",
      "   --- ----------------------------------- 14.0/159.7 MB 110.0 MB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 18.2/159.7 MB 110.0 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 22.2/159.7 MB 93.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 22.8/159.7 MB 65.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 26.8/159.7 MB 65.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 28.6/159.7 MB 59.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 29.2/159.7 MB 46.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 30.5/159.7 MB 40.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 30.6/159.7 MB 36.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 30.7/159.7 MB 29.8 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 30.8/159.7 MB 27.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 30.9/159.7 MB 23.4 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 31.1/159.7 MB 21.1 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 31.3/159.7 MB 19.8 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 31.5/159.7 MB 18.7 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 31.6/159.7 MB 17.2 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 31.6/159.7 MB 16.0 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 31.7/159.7 MB 14.6 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 31.8/159.7 MB 13.6 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 32.0/159.7 MB 12.8 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 32.4/159.7 MB 11.9 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 32.7/159.7 MB 11.9 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 32.8/159.7 MB 11.3 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 33.1/159.7 MB 10.7 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 33.6/159.7 MB 10.4 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 35.0/159.7 MB 10.1 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 38.2/159.7 MB 9.9 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 41.8/159.7 MB 17.2 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 46.6/159.7 MB 81.8 MB/s eta 0:00:02\n",
      "   ------------ -------------------------- 50.4/159.7 MB 108.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 50.5/159.7 MB 72.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 50.5/159.7 MB 54.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 50.6/159.7 MB 43.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 50.8/159.7 MB 36.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 51.0/159.7 MB 29.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 51.4/159.7 MB 27.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 51.7/159.7 MB 24.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 53.2/159.7 MB 22.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 58.2/159.7 MB 22.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 58.8/159.7 MB 21.8 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 59.0/159.7 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 59.1/159.7 MB 17.2 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 59.6/159.7 MB 16.4 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 60.0/159.7 MB 15.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 60.0/159.7 MB 14.6 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 60.1/159.7 MB 13.6 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 60.2/159.7 MB 12.8 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 60.4/159.7 MB 11.9 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 60.6/159.7 MB 11.3 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 64.4/159.7 MB 18.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 68.7/159.7 MB 18.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 70.4/159.7 MB 43.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 70.4/159.7 MB 38.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 70.6/159.7 MB 38.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 70.8/159.7 MB 34.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 71.5/159.7 MB 32.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 76.4/159.7 MB 32.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 80.9/159.7 MB 59.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 81.1/159.7 MB 59.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 81.6/159.7 MB 54.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 81.8/159.7 MB 50.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 81.8/159.7 MB 50.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 81.8/159.7 MB 50.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 81.8/159.7 MB 50.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 85.0/159.7 MB 26.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 85.1/159.7 MB 24.2 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 85.1/159.7 MB 22.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 85.2/159.7 MB 19.8 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 85.4/159.7 MB 17.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 85.5/159.7 MB 16.8 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 85.6/159.7 MB 15.6 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 85.9/159.7 MB 14.6 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 88.9/159.7 MB 13.9 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 90.4/159.7 MB 13.4 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 90.4/159.7 MB 12.6 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 90.5/159.7 MB 11.9 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 90.7/159.7 MB 11.3 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 91.0/159.7 MB 10.9 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 94.1/159.7 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 99.1/159.7 MB 31.2 MB/s eta 0:00:02\n",
      "   ------------------------ ------------- 104.2/159.7 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------- ------------ 109.1/159.7 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------------- ---------- 114.0/159.7 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------- --------- 118.5/159.7 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 118.7/159.7 MB 72.6 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 119.1/159.7 MB 54.7 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 119.5/159.7 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 123.2/159.7 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 128.2/159.7 MB 43.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 131.4/159.7 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 136.5/159.7 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 138.4/159.7 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 138.4/159.7 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 138.4/159.7 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 138.4/159.7 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 143.0/159.7 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 147.9/159.7 MB 38.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 150.9/159.7 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.3/159.7 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.4/159.7 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  155.8/159.7 MB 50.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  157.4/159.7 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  157.7/159.7 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.1/159.7 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.5/159.7 MB 29.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 159.7/159.7 MB 18.2 MB/s eta 0:00:00\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Using cached tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 109.2 MB/s eta 0:00:00\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tbb, mpmath, intel-openmp, sympy, networkx, mkl, fsspec, filelock, torch\n",
      "Successfully installed filelock-3.14.0 fsspec-2024.3.1 intel-openmp-2021.4.0 mkl-2021.4.0 mpmath-1.3.0 networkx-3.2.1 sympy-1.12 tbb-2021.12.0 torch-2.3.0\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Using cached huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.4.28-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.9/41.9 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Using cached transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
      "Using cached huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "Downloading regex-2024.4.28-cp39-cp39-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/269.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 269.0/269.0 kB 16.2 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp39-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 287.9/287.9 kB ? eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 147.4 MB/s eta 0:00:00\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.23.0 regex-2024.4.28 safetensors-0.4.3 tokenizers-0.19.1 tqdm-4.66.2 transformers-4.40.1\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.43.1-py3-none-win_amd64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from bitsandbytes) (2.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch->bitsandbytes) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch->bitsandbytes) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch->bitsandbytes) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch->bitsandbytes) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->bitsandbytes) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->bitsandbytes) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Using cached bitsandbytes-0.43.1-py3-none-win_amd64.whl (101.6 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.43.1\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Using cached accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.29.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install bitsandbytes\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cdb670e-46f5-4968-b460-3a905c29228f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\dmlql\\.conda\\envs\\llm_project\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dmlql\\.conda\\envs\\llm_project\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dmlql\\.conda\\envs\\llm_project\\lib\\site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dmlql\\.conda\\envs\\llm_project\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.5 MB 960.0 kB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 1.6/11.5 MB 20.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.7/11.5 MB 37.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.7/11.5 MB 39.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.6/11.5 MB 39.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.5 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.5 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 40.9 MB/s eta 0:00:00\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 345.4/345.4 kB 20.9 MB/s eta 0:00:00\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7333bc5f-edfe-4287-8e3c-e6ded7ee33d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c3bafc-21e2-4bc1-85bd-09472a1f2280",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a7d05c1ca94daaa0eca91431e58fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 허깅페이스 로그인\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b962f41-ae16-4f8c-be9a-33b9af2dd5a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HF_TOKEN = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbce6b69-6657-4079-ad8e-67dc6e7dac57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WORK_DIR = 'C:/Users/dmlql/KT_AIVLE/Project/증시 상황 요약 LLM Chat bot/'\n",
    "ARTICLE_PATH = os.path.join(WORK_DIR, 'articles_db.json')                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9628cc-b3cd-447f-bde0-e61f4c2f593d",
   "metadata": {},
   "source": [
    "### 2. 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff956b3-8a2a-43f0-ad92-1203b695d3eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"microsoft/Phi-3-mini-128k-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62f08798-14be-4d58-8e31-9eb867b6da51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmlql\\.conda\\envs\\LLM_project\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb552db197148dfabbd716f03a5afae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                            bnb_4bit_compute_dtype = torch.float16,\n",
    "                            bnb_4bit_quant_type = 'nf4',\n",
    "                            llm_int8_enable_fp32_cpu_offload=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    quantization_config=quantization_config,\n",
    "    trust_remote_code=True,\n",
    "    token=HF_TOKEN\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID,\n",
    "                                          add_special_tokens=True,\n",
    "                                          toekn=HF_TOKEN)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=32064\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e0f118b-4775-4d10-b97a-f50c10b19e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_prompt(article_list, pipe):\n",
    "    chat = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\n",
    "        }\n",
    "    ]\n",
    "    content = f'''아래 문서 내용만을 참조하여 질문에 답해줘.\n",
    "    문서 : {article_list[0]}\n",
    "\n",
    "    [질문] 문서의 내용을 보고 '긍정' 또는 '부정'으로 판단해줘!\n",
    "    '''\n",
    "\n",
    "    chat[0]['content'] = content\n",
    "    prompt = pipe.tokenizer.apply_chat_template(chat,\n",
    "                                            tokenize=False,\n",
    "                                            add_generation_prompt=True)\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eddea72-2145-4b87-97c6-79e326cd6f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57f6ca5db3b44dbb008dd0ca1b3cb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing items: 0item [00:00, ?item/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    }
   ],
   "source": [
    "article_list= []\n",
    "with open(ARTICLE_PATH, 'r+', encoding='utf-8') as f:\n",
    "    for i, line in tqdm(enumerate(f), desc=\"Processing items\", unit='item'):\n",
    "        article_list.append(json.loads(line)['content'])\n",
    "\n",
    "prompt = gen_prompt(article_list, pipe)\n",
    "outputs = pipe(\n",
    "            prompt,\n",
    "            do_sample=True,\n",
    "            temperature=0.2,\n",
    "            top_k=50,\n",
    "            top_p=0.95,  \n",
    "            add_special_tokens=True\n",
    "        )\n",
    "print(outputs[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e826aa6-b158-49b7-b414-1c45dccb05d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmlql\\.conda\\envs\\LLM_project\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3956dbf61e4d4740a68200acdd6daaab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "C:\\Users\\dmlql\\.conda\\envs\\LLM_project\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:671: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\", model=model_id, model_kwargs={\"torch_dtype\": torch.bfloat16}, device_map=\"auto\"\n",
    ")\n",
    "pipeline(\"Hey how are you doing today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2267b06-ace8-48e2-b9ff-1fc095d6cf47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
