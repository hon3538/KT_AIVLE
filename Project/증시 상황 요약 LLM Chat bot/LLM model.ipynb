{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30aac96c-8df6-4e87-9f72-46c85206bdb0",
   "metadata": {},
   "source": [
    "# Hugging Face의 LLM 모델 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d67273e-0287-47b7-8cca-c31c87eb3d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     C:\\ProgramData\\anaconda3\n",
      "LLM_project              C:\\Users\\dmlql\\.conda\\envs\\LLM_project\n",
      "gpu-test              *  C:\\Users\\dmlql\\.conda\\envs\\gpu-test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info --envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3c55fc8-8544-44c7-9903-5808784570d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 23.3.1 from C:\\Users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages\\pip (python 3.9)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a108b8a-235f-4a4e-9278-5b0d20ed0987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 24.4.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.4.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install tensorflow-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f935d1-9790-4932-ad10-e5a42e1684ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\dmlql\\\\.conda\\\\envs\\\\gpu-test\\\\lib\\\\site-packages\\\\keras\\\\api\\\\_v2',\n",
       " 'C:\\\\Users\\\\dmlql\\\\.conda\\\\envs\\\\gpu-test\\\\lib\\\\site-packages\\\\keras\\\\_tf_keras',\n",
       " 'C:\\\\Users\\\\dmlql\\\\.conda\\\\envs\\\\gpu-test\\\\lib\\\\site-packages\\\\tensorflow',\n",
       " 'C:\\\\Users\\\\dmlql\\\\.conda\\\\envs\\\\gpu-test\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9957030a-3bbc-4062-8764-714aba0d7b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3078833814771650781\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7c3b29-6ff4-40a3-8926-94f40f390e1c",
   "metadata": {},
   "source": [
    "### 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50c4e274-ef20-44e1-8126-f075873d95f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8176556296534719083\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# gpu 확인\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3badf7e7-c025-4a62-8475-86839055d80e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\dmlql\\\\KT_AIVLE\\\\Project\\\\증시 상황 요약 LLM Chat bot',\n",
       " 'C:\\\\Users\\\\dmlql\\\\.conda\\\\envs\\\\gpu-test\\\\python39.zip',\n",
       " 'C:\\\\Users\\\\dmlql\\\\.conda\\\\envs\\\\gpu-test\\\\DLLs',\n",
       " 'C:\\\\Users\\\\dmlql\\\\.conda\\\\envs\\\\gpu-test\\\\lib',\n",
       " 'C:\\\\Users\\\\dmlql\\\\.conda\\\\envs\\\\gpu-test',\n",
       " '',\n",
       " 'C:\\\\Users\\\\dmlql\\\\.conda\\\\envs\\\\gpu-test\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\dmlql\\\\.conda\\\\envs\\\\gpu-test\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\dmlql\\\\.conda\\\\envs\\\\gpu-test\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\dmlql\\\\.conda\\\\envs\\\\gpu-test\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\ProgramData\\\\anaconda3',\n",
       " 'C:\\\\ProgramData\\\\anaconda3\\\\Lib\\\\site-packages']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\ProgramData\\\\anaconda3\\\\Lib\\\\site-packages')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c096489-2c66-40c0-9233-6cc057de34e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May  3 02:22:46 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 537.13                 Driver Version: 537.13       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080      WDDM  | 00000000:0A:00.0  On |                  N/A |\n",
      "| 35%   33C    P8              23W / 225W |   1001MiB /  8192MiB |      3%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1832    C+G   ...on\\124.0.2478.67\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A      7060    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      8664    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      8816    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11036    C+G   ...B\\system_tray\\lghub_system_tray.exe    N/A      |\n",
      "|    0   N/A  N/A     11164    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     11764    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12536    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     24580    C+G   ...__wyx1vj98g3asy\\Win32\\QSSystray.exe    N/A      |\n",
      "|    0   N/A  N/A     26836    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea9cf8b-f2dc-4b36-a339-3f7ea2fb25a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.3.0-cp39-cp39-win_amd64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch) (4.9.0)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch) (3.1.3)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Using cached tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.3.0-cp39-cp39-win_amd64.whl (159.7 MB)\n",
      "   ---------------------------------------- 0.0/159.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 4.4/159.7 MB 136.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 9.4/159.7 MB 119.3 MB/s eta 0:00:02\n",
      "   --- ----------------------------------- 14.0/159.7 MB 110.0 MB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 18.2/159.7 MB 110.0 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 22.2/159.7 MB 93.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 22.8/159.7 MB 65.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 26.8/159.7 MB 65.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 28.6/159.7 MB 59.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 29.2/159.7 MB 46.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 30.5/159.7 MB 40.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 30.6/159.7 MB 36.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 30.7/159.7 MB 29.8 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 30.8/159.7 MB 27.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 30.9/159.7 MB 23.4 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 31.1/159.7 MB 21.1 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 31.3/159.7 MB 19.8 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 31.5/159.7 MB 18.7 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 31.6/159.7 MB 17.2 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 31.6/159.7 MB 16.0 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 31.7/159.7 MB 14.6 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 31.8/159.7 MB 13.6 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 32.0/159.7 MB 12.8 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 32.4/159.7 MB 11.9 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 32.7/159.7 MB 11.9 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 32.8/159.7 MB 11.3 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 33.1/159.7 MB 10.7 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 33.6/159.7 MB 10.4 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 35.0/159.7 MB 10.1 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 38.2/159.7 MB 9.9 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 41.8/159.7 MB 17.2 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 46.6/159.7 MB 81.8 MB/s eta 0:00:02\n",
      "   ------------ -------------------------- 50.4/159.7 MB 108.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 50.5/159.7 MB 72.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 50.5/159.7 MB 54.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 50.6/159.7 MB 43.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 50.8/159.7 MB 36.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 51.0/159.7 MB 29.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 51.4/159.7 MB 27.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 51.7/159.7 MB 24.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 53.2/159.7 MB 22.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 58.2/159.7 MB 22.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 58.8/159.7 MB 21.8 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 59.0/159.7 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 59.1/159.7 MB 17.2 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 59.6/159.7 MB 16.4 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 60.0/159.7 MB 15.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 60.0/159.7 MB 14.6 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 60.1/159.7 MB 13.6 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 60.2/159.7 MB 12.8 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 60.4/159.7 MB 11.9 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 60.6/159.7 MB 11.3 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 64.4/159.7 MB 18.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 68.7/159.7 MB 18.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 70.4/159.7 MB 43.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 70.4/159.7 MB 38.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 70.6/159.7 MB 38.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 70.8/159.7 MB 34.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 71.5/159.7 MB 32.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 76.4/159.7 MB 32.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 80.9/159.7 MB 59.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 81.1/159.7 MB 59.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 81.6/159.7 MB 54.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 81.8/159.7 MB 50.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 81.8/159.7 MB 50.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 81.8/159.7 MB 50.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 81.8/159.7 MB 50.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 85.0/159.7 MB 26.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 85.1/159.7 MB 24.2 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 85.1/159.7 MB 22.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 85.2/159.7 MB 19.8 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 85.4/159.7 MB 17.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 85.5/159.7 MB 16.8 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 85.6/159.7 MB 15.6 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 85.9/159.7 MB 14.6 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 88.9/159.7 MB 13.9 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 90.4/159.7 MB 13.4 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 90.4/159.7 MB 12.6 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 90.5/159.7 MB 11.9 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 90.7/159.7 MB 11.3 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 91.0/159.7 MB 10.9 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 94.1/159.7 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 99.1/159.7 MB 31.2 MB/s eta 0:00:02\n",
      "   ------------------------ ------------- 104.2/159.7 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------- ------------ 109.1/159.7 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------------- ---------- 114.0/159.7 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------- --------- 118.5/159.7 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 118.7/159.7 MB 72.6 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 119.1/159.7 MB 54.7 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 119.5/159.7 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 123.2/159.7 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 128.2/159.7 MB 43.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 131.4/159.7 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 136.5/159.7 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 138.4/159.7 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 138.4/159.7 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 138.4/159.7 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 138.4/159.7 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 143.0/159.7 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 147.9/159.7 MB 38.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 150.9/159.7 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.3/159.7 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.4/159.7 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  155.8/159.7 MB 50.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  157.4/159.7 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  157.7/159.7 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.1/159.7 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.5/159.7 MB 29.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 159.7/159.7 MB 18.2 MB/s eta 0:00:00\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Using cached tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 109.2 MB/s eta 0:00:00\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tbb, mpmath, intel-openmp, sympy, networkx, mkl, fsspec, filelock, torch\n",
      "Successfully installed filelock-3.14.0 fsspec-2024.3.1 intel-openmp-2021.4.0 mkl-2021.4.0 mpmath-1.3.0 networkx-3.2.1 sympy-1.12 tbb-2021.12.0 torch-2.3.0\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Using cached huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.4.28-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.9/41.9 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Using cached transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
      "Using cached huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "Downloading regex-2024.4.28-cp39-cp39-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/269.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 269.0/269.0 kB 16.2 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp39-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 287.9/287.9 kB ? eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 147.4 MB/s eta 0:00:00\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.23.0 regex-2024.4.28 safetensors-0.4.3 tokenizers-0.19.1 tqdm-4.66.2 transformers-4.40.1\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.43.1-py3-none-win_amd64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from bitsandbytes) (2.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch->bitsandbytes) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch->bitsandbytes) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch->bitsandbytes) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch->bitsandbytes) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->bitsandbytes) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->bitsandbytes) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Using cached bitsandbytes-0.43.1-py3-none-win_amd64.whl (101.6 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.43.1\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dmlql\\.conda\\envs\\gpu-test\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Using cached accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.29.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install bitsandbytes\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdb670e-46f5-4968-b460-3a905c29228f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7333bc5f-edfe-4287-8e3c-e6ded7ee33d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c3bafc-21e2-4bc1-85bd-09472a1f2280",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b107135884144fb486a32456ab318ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 허깅페이스 로그인\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b962f41-ae16-4f8c-be9a-33b9af2dd5a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HF_TOKEN = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbce6b69-6657-4079-ad8e-67dc6e7dac57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WORK_DIR = 'C:/Users/dmlql/KT_AIVLE/Project/증시 상황 요약 LLM Chat bot/'\n",
    "DATA_PATH = os.path.join(WORK_DIR, 'articles.json')                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9628cc-b3cd-447f-bde0-e61f4c2f593d",
   "metadata": {},
   "source": [
    "### 2. 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff956b3-8a2a-43f0-ad92-1203b695d3eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"microsoft/Phi-3-mini-128k-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62f08798-14be-4d58-8e31-9eb867b6da51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmlql\\.conda\\envs\\LLM_project\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(WORK_DIR\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLM_model\u001b[39m\u001b[38;5;124m'\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\LLM_project\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:558\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    559\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    560\u001b[0m     )\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[1;32m~\\.conda\\envs\\LLM_project\\Lib\\site-packages\\transformers\\modeling_utils.py:3165\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3162\u001b[0m     hf_quantizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3165\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mvalidate_environment(\n\u001b[0;32m   3166\u001b[0m         torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, from_tf\u001b[38;5;241m=\u001b[39mfrom_tf, from_flax\u001b[38;5;241m=\u001b[39mfrom_flax, device_map\u001b[38;5;241m=\u001b[39mdevice_map\n\u001b[0;32m   3167\u001b[0m     )\n\u001b[0;32m   3168\u001b[0m     torch_dtype \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_torch_dtype(torch_dtype)\n\u001b[0;32m   3169\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_device_map(device_map)\n",
      "File \u001b[1;32m~\\.conda\\envs\\LLM_project\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_4bit.py:62\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer.validate_environment\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_environment\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_accelerate_available() \u001b[38;5;129;01mand\u001b[39;00m is_bitsandbytes_available()):\n\u001b[1;32m---> 62\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     63\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m         )\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_tf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_flax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m sure the weights are in PyTorch format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m         )\n",
      "\u001b[1;31mImportError\u001b[0m: Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(WORK_DIR+'LM_model', trust_remote_code=True)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(WORK_DIR+'LM_tokenizer',\n",
    "#                                          trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f118b-4775-4d10-b97a-f50c10b19e91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
